{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder\n",
    "\n",
    "This notebook illustrate how to build and train a Variation AutoEncoder with the [beer framework](https://github.com/beer-asr/beer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"beer\" to the PYTHONPATH\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import copy\n",
    "\n",
    "import beer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For plotting.\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, gridplot\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "output_notebook()\n",
    "\n",
    "# Convenience functions for plotting.\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As an illustration, we generate a synthetic data set composed of two Normal distributed cluster.\n",
    "One has a diagonal covariance matrix whereas the other has a dense covariance matrix.\n",
    "Those two clusters overlap so it is reasonable to map all the data to a single Gaussian in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'\n",
    "download = False  # set to True if the line \"train_set = ...\" complains\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.RandomVerticalFlip(p=1.0),\n",
    "    transforms.ToTensor(), \n",
    "#    transforms.Normalize((0.5,), (1.0,)),\n",
    "])\n",
    "train_set = torchvision.datasets.MNIST(root=root, train=True, transform=trans, download=download)\n",
    "test_set = torchvision.datasets.MNIST(root=root, train=False, transform=trans)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_set,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_set,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_nb = 5\n",
    "fig = figure(x_range=[0, sqrt_nb*28], y_range=[0, sqrt_nb*28])\n",
    "for i in range(sqrt_nb):\n",
    "    for j in range(sqrt_nb):\n",
    "        fig.image(image=[X[i*sqrt_nb + j][0].numpy()], x=j*28, y=(sqrt_nb-i-1)*28, dw=27, dh=27)\n",
    "show(fig)\n",
    "\n",
    "print(t[:sqrt_nb**2].view(sqrt_nb,sqrt_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Model\n",
    "\n",
    "We build a VAE with Gaussian distribution in the latent space and Bernouli distribution on individual pixel in the observed space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_dim = 28*28\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 400\n",
    "\n",
    "enc_nn = torch.nn.Sequential(\n",
    "    torch.nn.Linear(observed_dim, hidden_dim),\n",
    "    torch.nn.Tanh(),\n",
    ")\n",
    "latent_dist_builder = beer.NormalDiagBuilder(latent_dim)\n",
    "enc_proto = beer.MLPModel(enc_nn, hidden_dim, latent_dist_builder)\n",
    "\n",
    "dec_nn = torch.nn.Sequential(    \n",
    "    torch.nn.Linear(latent_dim, hidden_dim),\n",
    "    torch.nn.Tanh(),\n",
    ")\n",
    "obs_dist_builder = beer.BernoulliBuilder(observed_dim)\n",
    "dec_proto = beer.MLPModel(dec_nn, hidden_dim, obs_dist_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "latent_normal = beer.NormalDiagonalCovariance(\n",
    "    prior=beer.NormalGammaPrior(torch.zeros(latent_dim), torch.ones(latent_dim), 1.),\n",
    "    posterior=beer.NormalGammaPrior(torch.zeros(latent_dim), torch.ones(latent_dim), 1.)\n",
    ")\n",
    "vae = beer.models.VAE(copy.deepcopy(enc_proto), copy.deepcopy(dec_proto), latent_normal, nsamples=1)\n",
    "mean_elbos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epochs):\n",
    "    for i in range(nb_epochs):\n",
    "        for X, _ in train_loader:\n",
    "            X = torch.autograd.Variable(X.view(-1, 28**2))\n",
    "            elbo = vae.forward(X)\n",
    "            obj = -elbo.mean()\n",
    "            mean_elbos.append(-obj.item())\n",
    "            optim.zero_grad()\n",
    "            obj.backward()\n",
    "            optim.step()\n",
    "        print(\"epoch {} done, last ELBO: {}\".format(i, mean_elbos[-1]))\n",
    "\n",
    "# a reasonable training procedure\n",
    "optim = torch.optim.Adam(list(vae.encoder.parameters()) + list(vae.decoder.parameters()), lr=1e-3)\n",
    "train(3)\n",
    "\n",
    "fig = figure(title='ELBO', width=400, height=400, x_axis_label='step',\n",
    "              y_axis_label='ln p(X)')\n",
    "fig.line(np.arange(len(mean_elbos)), mean_elbos, legend='ELBO', color='blue')\n",
    "fig.legend.location = 'bottom_right'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_nb = 15 # how many samples per axis\n",
    "\n",
    "# what range to cover. Note that it is a half range (2 <=> -2 -- +2).\n",
    "# Consult output of the next cell for optimal value\n",
    "latent_range = 4\n",
    "\n",
    "latent_step = 2*latent_range / (sqrt_nb-1) # -1 so that we can place the end ones on the ends\n",
    "latent_positions = [-latent_range + i*latent_step for i in range(sqrt_nb)]\n",
    "\n",
    "complete_range = [-latent_range-latent_step/2, latent_range+latent_step/2]\n",
    "fig = figure(x_range=complete_range, y_range=complete_range)\n",
    "for ly in latent_positions:\n",
    "    for lx in latent_positions:\n",
    "        latent_repre = torch.Tensor([lx, ly])\n",
    "        image = vae.decoder(torch.autograd.Variable(latent_repre)).mu\n",
    "        image = image.view(28,28).data\n",
    "        fig.image(\n",
    "            image=[image.numpy()], \n",
    "            x=lx-latent_step/2, y=ly-latent_step/2, \n",
    "            dw=latent_step, dh=latent_step\n",
    "        )\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_images = []\n",
    "ts = []\n",
    "for X, t in train_loader:\n",
    "    X = torch.autograd.Variable(X.view(-1, 28**2))\n",
    "    latent_images.append(vae.encoder(X).mean)\n",
    "    ts.append(t)\n",
    "    \n",
    "    \n",
    "latent_images = torch.cat(latent_images).data\n",
    "ts = torch.cat(ts).data\n",
    "print(latent_images.mean(dim=0))\n",
    "\n",
    "#           0      1       2          3        4       5        6         7        8         9\n",
    "colors = ['red', 'blue', 'green', 'purple', 'black', 'cyan', 'yellow', 'brown', 'violet', 'olive']\n",
    "fig = figure(\n",
    "    title='p(X)', width=400, height=400, \n",
    "    x_range=[-latent_range, latent_range], y_range=[-latent_range, latent_range]\n",
    ")\n",
    "for i in range(10): # plot each digit seperately\n",
    "    mask = (ts == i).nonzero().view(-1)\n",
    "    selection = latent_images[mask]\n",
    "    fig.circle(selection[:,0].numpy(), selection[:,1].numpy(), color=colors[i], size=0.4)\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
