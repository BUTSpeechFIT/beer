{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Mixture Model\n",
    "\n",
    "This notebook illustrate how to build and train a Bayesian Mixture Model with the [beer framework](https://github.com/beer-asr/beer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"beer\" to the PYTHONPATH\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import copy\n",
    "\n",
    "import beer\n",
    "import numpy as np\n",
    "\n",
    "# For plotting.\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, gridplot\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "output_notebook()\n",
    "\n",
    "# Convenience functions for plotting.\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As an illustration, we generate a synthetic data set composed of two Normal distributed cluster. One has a diagonal covariance matrix whereas the other has a dense covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First cluster.\n",
    "mean = np.array([-1.5, 4]) \n",
    "cov = np.array([[.75, 0], [0, 2.]])\n",
    "data1 = np.random.multivariate_normal(mean, cov, size=100)\n",
    "\n",
    "# Second cluster.\n",
    "mean = np.array([5, 5]) \n",
    "cov = np.array([[2, 1], [1, .75]])\n",
    "data2 = np.random.multivariate_normal(mean, cov, size=100)\n",
    "\n",
    "# Merge everything to get the finale data set.\n",
    "data = np.vstack([data1, data2])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, variance of the data to scale the figure.\n",
    "mean = data.mean(axis=0)\n",
    "var = data.var(axis=0)\n",
    "std_dev = np.sqrt(max(var))\n",
    "x_range = (mean[0] - 2 * std_dev, mean[0] + 2 * std_dev)\n",
    "y_range = (mean[1] - 2 * std_dev, mean[1] + 2 * std_dev)\n",
    "global_range = (min(x_range[0], y_range[0]), max(x_range[1], y_range[1]))\n",
    "\n",
    "fig = figure(title='Data', width=400, height=400,\n",
    "             x_range=global_range, y_range=global_range)\n",
    "fig.circle(data[:, 0], data[:, 1])\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "We create two types of mixture model: one whose (Normal) components have full covariance matrix and the other whose (Normal) components have diagonal covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use the global mean/cov. matrix of the data to initialize the mixture.\n",
    "p_mean = data.mean(axis=0)\n",
    "p_cov = np.cov(data.T)\n",
    "\n",
    "# Create the models.\n",
    "args = {'dim':2, 'mean':p_mean, 'cov': p_cov, 'prior_count':1, 'random_init':True}\n",
    "gmm_diag = beer.Mixture.create(10, beer.NormalDiagonalCovariance.create, args, prior_count=1)\n",
    "gmm_full = beer.Mixture.create(10, beer.NormalFullCovariance.create, args, prior_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayes Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback to monitor the training progress.\n",
    "elbos, llhs, klds = [], [], []\n",
    "def callback(elbo, llh, kld):\n",
    "    elbos.append(elbo)\n",
    "    llhs.append(llh)\n",
    "    klds.append(kld)\n",
    "\n",
    "# Train the GMM with diagonal cov. matrix components.\n",
    "gmm_diag.fit(data, max_epochs=200, callback=callback)\n",
    "elbos_diag = copy.deepcopy(elbos[1:])\n",
    "llhs_diag =  copy.deepcopy(llhs[1:])\n",
    "klds_diag = copy.deepcopy(klds[1:])\n",
    "\n",
    "# Re-initialize the training progress.\n",
    "elbos, llhs, klds = [], [], []\n",
    "\n",
    "# Train the GMM with full cov. matrix components.\n",
    "gmm_full.fit(data, max_epochs=200, callback=callback)\n",
    "elbos_full = copy.deepcopy(elbos[1:])\n",
    "llhs_full =  copy.deepcopy(llhs[1:])\n",
    "klds_full = copy.deepcopy(klds[1:])\n",
    "\n",
    "# Plot the ELBO.\n",
    "fig = figure(title='ELBO', width=400, height=400, x_axis_label='step',\n",
    "              y_axis_label='ln p(X)')\n",
    "fig.line(np.arange(len(elbos_diag)), elbos_diag, legend='GMM (diag)', color='blue')\n",
    "#fig.line(np.arange(len(elbos_full)), elbos_full, legend='GMM (full)', color='red')\n",
    "fig.legend.location = 'bottom_right'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1 = figure(title='GMM (diag)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig1.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig1, gmm_diag, color='blue')\n",
    "\n",
    "fig2 = figure(title='GMM (full)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig2.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig2, gmm_full, color='red')\n",
    "\n",
    "grid = gridplot([[fig1, fig2]])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split-VB algorithm\n",
    "\n",
    "The VB algorithm is sensitive to the initialization of the posterior distribution and may end up in a local maximum. The basic strategy used above is to initialize randomly the posterior distribution of the Normal components. This may not be desirable in all situtation as it can lead to poor covering of the space by the clusters. An alternative is the \"split-VB\" algorithm. This algorithm consists in fitting a Normal distribution to the data and then to split this distribtution into 2 other Normal distribution. Then, the process is repeated: we train using VB these 2 Normal distributions and split them again, ... until we reach the desire number of components. The splitting is done by moving the mean of the Normal distribution along the axis with the highest variability.\n",
    "\n",
    "Here is an example of splitting a mixture model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_diag_split = gmm_diag.split()\n",
    "gmm_full_split = gmm_full.split()\n",
    "\n",
    "fig1 = figure(title='GMM (diag)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig1.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig1, gmm_diag, color='blue')\n",
    "\n",
    "fig2 = figure(title='GMM (full)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig2.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig2, gmm_full, color='red')\n",
    "\n",
    "fig3 = figure(title='GMM splitted (diag)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig3.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig3, gmm_diag_split, color='blue')\n",
    "\n",
    "fig4 = figure(title='GMM splitted (full)', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig4.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig4, gmm_full_split, color='red')\n",
    "\n",
    "grid = gridplot([[fig1, fig2], [fig3, fig4]])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the VB algorithm with random initialization to the split-VB training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we run 10 times the standard VB training.\n",
    "elbos_vb = []\n",
    "for i in range(1):\n",
    "    args = {'dim':2, 'mean':p_mean, 'cov': p_cov, 'prior_count':1, 'random_init':True}\n",
    "    gmm_full = beer.Mixture.create(16, beer.NormalFullCovariance.create, args, prior_count=1e-3)\n",
    "    \n",
    "    elbos = []\n",
    "    def callback(elbo, llh, kld):\n",
    "        elbos.append(elbo)\n",
    "    gmm_full.fit(data, max_epochs=200, callback=callback)\n",
    "    elbos_vb.append(elbos[-1])\n",
    "    \n",
    "# New we run 10 times the split VB training.\n",
    "elbos_split_vb = []\n",
    "for i in range(1):\n",
    "    final_elbo = 0\n",
    "    def callback(elbo, llh, kld):\n",
    "        global final_elbo\n",
    "        final_elbo = elbo\n",
    "        \n",
    "    args = {'dim':2, 'mean':p_mean, 'cov': p_cov, 'prior_count':1, 'random_init':False}\n",
    "    gmm_full_split = beer.Mixture.create(1, beer.NormalFullCovariance.create, args, prior_count=1e-6)\n",
    "    gmm_full_split.fit(data, max_epochs=100)\n",
    "\n",
    "    for k in range(2):\n",
    "        gmm_full_split = gmm_full_split.split()\n",
    "        gmm_full_split.fit(data, max_epochs=100, callback=callback)\n",
    "    gmm_full_split.fit(data, max_epochs=1000, callback=callback)\n",
    "    elbos_split_vb.append(final_elbo)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = figure(title='GMM (full)', x_range=x_range, y_range=y_range,\n",
    "              width=400, height=400)\n",
    "fig1.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig1, gmm_full, color='blue')\n",
    "\n",
    "fig2 = figure(title='GMM splitted (full)', x_range=x_range, y_range=y_range,\n",
    "              width=400, height=400)\n",
    "fig2.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "plotting.plot_gmm(fig2, gmm_full_split, color='red')\n",
    "\n",
    "grid = gridplot([[fig1, fig2]])\n",
    "show(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
