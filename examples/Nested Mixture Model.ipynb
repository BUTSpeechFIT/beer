{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Nested Mixture Model\n",
    "\n",
    "This notebook illustrate how to build and train a Bayesian Nested Mixture Model with the [beer framework](https://github.com/beer-asr/beer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"beer\" to the PYTHONPATH\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import copy\n",
    "\n",
    "import beer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# For plotting.\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, gridplot\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "output_notebook()\n",
    "\n",
    "# Convenience functions for plotting.\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "As an illustration, we generate a synthetic data set composed of two Normal distributed cluster. One has a diagonal covariance matrix whereas the other has a dense covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cluster.\n",
    "mean = np.array([-5, 5]) \n",
    "cov = .5 *np.array([[.75, .5], [.5, 2.]])\n",
    "data1 = np.random.multivariate_normal(mean, cov, size=200)\n",
    "\n",
    "# Second cluster.\n",
    "mean = np.array([5, 5]) \n",
    "cov = 2 * np.array([[2, -.5], [-.5, .75]])\n",
    "data2 = np.random.multivariate_normal(mean, cov, size=200)\n",
    "\n",
    "# Merge everything to get the finale data set.\n",
    "data = np.vstack([data1, data2])\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# We use the global mean/cov. matrix of the data to initialize the mixture.\n",
    "data_mean = torch.from_numpy(data.mean(axis=0)).float()\n",
    "data_var = torch.from_numpy(np.var(data, axis=0)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, variance of the data to scale the figure.\n",
    "mean = data.mean(axis=0)\n",
    "var = data.var(axis=0)\n",
    "std_dev = np.sqrt(max(var))\n",
    "x_range = (mean[0] - 2 * std_dev, mean[0] + 2 * std_dev)\n",
    "y_range = (mean[1] - 2 * std_dev, mean[1] + 2 * std_dev)\n",
    "global_range = (min(x_range[0], y_range[0]), max(x_range[1], y_range[1]))\n",
    "\n",
    "fig = figure(title='Data', width=400, height=400,\n",
    "             x_range=global_range, y_range=global_range)\n",
    "fig.circle(data[:, 0], data[:, 1])\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "We create two types of mixture model: one whose (Normal) components have full covariance matrix and the other whose (Normal) components have diagonal covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_template = '''\n",
    "type: Mixture\n",
    "prior_strength: 1.\n",
    "components:\n",
    "    type: MixtureSet\n",
    "    size: {size}\n",
    "    prior_strength: 1.\n",
    "    components: \n",
    "        type: NormalSet\n",
    "        size: 1\n",
    "        covariance: {cov_type}\n",
    "        shared_covariance: {shared_cov}\n",
    "        prior_strength: 1.e-1\n",
    "        noise_std: .5\n",
    "'''\n",
    "\n",
    "confs = [\n",
    "    conf_template.format(size=2, cov_type='isotropic', shared_cov=False),\n",
    "    conf_template.format(size=2, cov_type='diagonal', shared_cov=False),\n",
    "    conf_template.format(size=2, cov_type='full', shared_cov=False),\n",
    "    conf_template.format(size=2, cov_type='isotropic', shared_cov=True),\n",
    "    conf_template.format(size=2, cov_type='diagonal', shared_cov=True),\n",
    "    conf_template.format(size=2, cov_type='full', shared_cov=True)\n",
    "]\n",
    "\n",
    "names = [\n",
    "    'm_gmm_iso', \n",
    "    'm_gmm_diag', \n",
    "    'm_gmm_full', \n",
    "    'm_gmm_iso_shared', \n",
    "    'm_gmm_diag_shared', \n",
    "    'm_gmm_full_shared'\n",
    "]\n",
    "\n",
    "import yaml\n",
    "models = {\n",
    "    name: beer.create_model(yaml.load(conf), data_mean, .1 * data_var)\n",
    "    for name, conf in zip(names, confs)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayes Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lrate = 1.\n",
    "X = torch.from_numpy(data).float()\n",
    "\n",
    "optims = {\n",
    "    model_name: beer.BayesianModelCoordinateAscentOptimizer(model.mean_field_groups, lrate)\n",
    "    for model_name, model in models.items()\n",
    "}\n",
    "\n",
    "elbos = {\n",
    "    model_name: [] \n",
    "    for model_name in models\n",
    "}  \n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    for name, model in models.items():\n",
    "        optim = optims[name]\n",
    "        optim.zero_grad()\n",
    "        elbo = beer.evidence_lower_bound(model, X, datasize=len(X))\n",
    "        elbo.natural_backward()\n",
    "        elbos[name].append(float(elbo) / len(X))\n",
    "        optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'm_gmm_iso': 'green',\n",
    "    'm_gmm_diag': 'blue',\n",
    "    'm_gmm_full': 'red',\n",
    "    'm_gmm_iso_shared': 'grey',\n",
    "    'm_gmm_diag_shared': 'brown',\n",
    "    'm_gmm_full_shared': 'black'\n",
    "}\n",
    "# Plot the ELBO.\n",
    "fig = figure(title='ELBO', width=400, height=400, x_axis_label='step',\n",
    "              y_axis_label='ln p(X)')\n",
    "for model_name, elbo in elbos.items():\n",
    "    fig.line(range(len(elbo)), elbo, legend=model_name, color=colors[model_name])\n",
    "fig.legend.location = 'bottom_right'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figs = []\n",
    "for i, model_name in enumerate(models):\n",
    "    fig = figure(title=model_name, x_range=global_range, y_range=global_range,\n",
    "                  width=300, height=300)\n",
    "    model = models[model_name]\n",
    "    for gmm in model.modelset:\n",
    "        fig.circle(data[:, 0], data[:, 1], alpha=.1)\n",
    "        plotting.plot_gmm(fig, gmm, alpha=.5)\n",
    "    if i % 3 == 0:\n",
    "        figs.append([])\n",
    "    figs[-1].append(fig)\n",
    "grid = gridplot(figs)\n",
    "show(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
