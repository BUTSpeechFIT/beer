{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Normal Density\n",
    "\n",
    "This notebook illustrate how to use a Bayesian Normal density model with the [beer framework](https://github.com/beer-asr/beer). The Normal distribution is a fairly basic model but it is used extenslively in other model as a basic building block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"beer\" to the PYTHONPATH\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import beer\n",
    "import numpy as np\n",
    "\n",
    "# For plotting.\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, gridplot\n",
    "output_notebook()\n",
    "\n",
    "# Convenience functions for plotting.\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Generate some normally distributed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([-1.5, 4]) \n",
    "cov = np.array([\n",
    "    [2, 1],\n",
    "    [1, .75]\n",
    "])\n",
    "data = np.random.multivariate_normal(mean, cov, size=100)\n",
    "\n",
    "fig = figure(\n",
    "    title='Data',\n",
    "    width=400,\n",
    "    height=400,\n",
    "    x_range=(mean[0] - 5, mean[0] + 5),\n",
    "    y_range=(mean[1] - 5, mean[1] + 5)\n",
    ")\n",
    "fig.circle(data[:, 0], data[:, 1])\n",
    "plotting.plot_normal(fig, mean, cov)\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "We create two types of Normal distribution: one diagonal covariance matrix and another one with full covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_diag = beer.NormalDiagonalCovariance.create(dim=2, prior_count=1e-6)\n",
    "normal_full = beer.NormalFullCovariance.create(dim=2, prior_count=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayes Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training.\n",
    "beer.train_loglinear_model(normal_diag, data)\n",
    "beer.train_loglinear_model(normal_full, data)\n",
    "\n",
    "fig = figure(\n",
    "    title='Initial model',\n",
    "    width=400,\n",
    "    height=400,\n",
    "    x_range=(mean[0] - 5, mean[0] + 5),\n",
    "    y_range=(mean[1] - 5, mean[1] + 5)\n",
    ")\n",
    "fig.circle(data[:, 0], data[:, 1])\n",
    "plotting.plot_normal(fig, normal_diag.mean, normal_diag.cov, alpha=.5, color='red')\n",
    "plotting.plot_normal(fig, normal_full.mean, normal_full.cov, alpha=.5, color='green')\n",
    "\n",
    "show(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison\n",
    "\n",
    "We generate data for various corrleation parameters:\n",
    "\n",
    "$$\n",
    "X_{\\lambda} \\sim \\mathcal{N}(\n",
    "    \\begin{pmatrix} \n",
    "    0 \\\\\n",
    "    0\n",
    "    \\end{pmatrix}, \n",
    "    \\begin{pmatrix} \n",
    "    1 & \\lambda \\\\\n",
    "    \\lambda & 1\n",
    "    \\end{pmatrix})\n",
    "$$\n",
    "\n",
    "and we compare the model evidence for both the Normal distribution with diagonal covariance matrix and with full covariance matrix.\n",
    "\n",
    "$$\n",
    "\\ln B_{\\lambda} = \\ln \\frac{p(X_\\lambda | \\mathcal{M}_{\\text{full}})}{p(X_\\lambda | \\mathcal{M}_{\\text{diag}})} =\n",
    "     \\ln \\frac{\\int_{\\theta} p(X_\\lambda | \\theta, \\mathcal{M}_{\\text{full}}) p(\\theta) d\\theta}{\\int_{\\theta}p(X_\\lambda | \\theta, \\mathcal{M}_{\\text{diag}})p(\\theta) d\\theta} = \\frac{A_{\\text{full}}(\\xi + \\sum_{n=1}^N T(x_n)) - A_{\\text{full}}(\\xi)}{A_{\\text{diag}}(\\xi + \\sum_{n=1}^N T(x_n))\n",
    "     - A_{\\text{diag}}(\\xi)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "import copy\n",
    "\n",
    "lambdas = np.linspace(-.99, .99, 100)\n",
    "lBs = []\n",
    "\n",
    "# For each value of lambda.\n",
    "for l in lambdas:\n",
    "    # Generate the data.\n",
    "    cov = np.array([\n",
    "        [1, l],\n",
    "        [l, 1]\n",
    "    ])\n",
    "    X = np.random.multivariate_normal(np.zeros(2), cov, size=1000)\n",
    "\n",
    "    # Fit both models\n",
    "    normal_diag = beer.NormalDiagonalCovariance.create(dim=2, prior_count=1e-6)\n",
    "    beer.train_loglinear_model(normal_diag, X)\n",
    "    normal = beer.NormalFullCovariance.create(dim=2, mean=mean, prior_count=1e-6)\n",
    "    beer.train_loglinear_model(normal, X)\n",
    "    \n",
    "    # Compute the log Bayes factor.\n",
    "    llh_M1 = normal.posterior.lognorm() - normal.prior.lognorm()\n",
    "    llh_M2 = normal_diag.posterior.lognorm() - normal_diag.prior.lognorm()\n",
    "    lBs.append(llh_M1 - llh_M2)\n",
    "\n",
    "fig1 = figure(\n",
    "    title='Model Comparison',\n",
    "    x_axis_label='Î»',\n",
    "    y_axis_label='log Bayes factor',\n",
    "    width=400,\n",
    "    height=400\n",
    ")\n",
    "fig1.line(lambdas, lBs)\n",
    "\n",
    "show(fig1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
