{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian HMM Model\n",
    "\n",
    "This notebook illustrate how to build and train a Bayesian Hidden Markov Model with the [beer framework](https://github.com/beer-asr/beer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"beer\" to the PYTHONPATH\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import copy\n",
    "\n",
    "import beer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# For plotting.\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.plotting import figure, gridplot\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "output_notebook()\n",
    "\n",
    "# Convenience functions for plotting.\n",
    "import plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ali_trans_mat(tot_states):\n",
    "    '''Create align transition matrix for a sequence of units\n",
    "    Args:\n",
    "        tot_states (int): length of total number of states of the given\n",
    "            sequence.\n",
    "    '''\n",
    "\n",
    "    trans_mat = torch.diag(torch.ones(tot_states) * .5)\n",
    "    idx1 = torch.arange(0, tot_states-1, dtype=torch.long)\n",
    "    idx2 = torch.arange(1, tot_states, dtype=torch.long)\n",
    "    trans_mat[idx1, idx2] = .5\n",
    "    trans_mat[-1, -1] = 1.\n",
    "    return trans_mat\n",
    "\n",
    "    \n",
    "# Sequence: AB\n",
    "\n",
    "seqs = ['A', 'B', 'A']\n",
    "nsamples = 30\n",
    "ndim = 2\n",
    "\n",
    "units = ['A', 'B']\n",
    "len_seqs = len(seqs)\n",
    "num_unit_states = 3\n",
    "tot_states = len(seqs) * num_unit_states\n",
    "\n",
    "trans_mat = create_ali_trans_mat(tot_states)\n",
    "\n",
    "means = [np.array([-1.5, 3]), np.array([-1.5, 4]), np.array([-1.5, 5]),\n",
    "         np.array([1, -3]), np.array([1, -2]), np.array([1, -1])]\n",
    "covs = [np.array([[.75, -.5], [-.5, 2.]]), np.array([[.75, -.5], [-.5, 2.]]), np.array([[.75, -.5], [-.5, 2.]]),\n",
    "        np.array([[2, 1], [1, .75]]), np.array([[2, 1], [1, .75]]), np.array([[2, 1], [1, .75]])]\n",
    "\n",
    "states_id = {'A':[0, 1, 2], 'B':[3, 4, 5]}\n",
    "dict_seq_state = {}\n",
    "\n",
    "seqs_id = []\n",
    "for i, j in enumerate(seqs):\n",
    "    for u in range(num_unit_states):\n",
    "        dict_seq_state[num_unit_states * i + u] = states_id[j][u]\n",
    "        seqs_id.append(states_id[j][u])\n",
    "\n",
    "normal_sets = list(zip(means,covs))\n",
    "\n",
    "states = np.zeros(nsamples, dtype=np.int16)\n",
    "data = np.zeros((nsamples, ndim))\n",
    "states[0] = states_id['A'][0]\n",
    "data[0] = np.random.multivariate_normal(means[0], covs[0], size=1)\n",
    "\n",
    "colors = ['blue', 'blue', 'blue', 'red', 'red', 'red']\n",
    "fig1 = figure(title='Samples', width=400, height=400)\n",
    "fig1.circle(data[0, 0], data[0, 1], color=colors[states[0]])\n",
    "\n",
    "\n",
    "for n in range(1, nsamples):\n",
    "    states[n] = np.random.choice(np.arange(tot_states), p=trans_mat[states[n-1]].numpy())\n",
    "    data[n] = np.random.multivariate_normal(means[dict_seq_state[states[n]]], covs[dict_seq_state[states[n]]], size=1)\n",
    "    fig1.circle(data[n, 0], data[n, 1], color=colors[dict_seq_state[states[n]]], line_width=1)\n",
    "    fig1.line(data[n-1:n+1, 0], data[n-1:n+1, 1], color='black', line_width=.5, alpha=.5)\n",
    "\n",
    "states_id = [dict_seq_state[i] for i in states]\n",
    "    \n",
    "fig2 = figure(title='Emissions',  width=400, height=400)\n",
    "colors = ['darkblue', 'blue', 'skyblue', 'darkred','red', 'pink']\n",
    "\n",
    "for i, n in enumerate(normal_sets):\n",
    "    plotting.plot_normal(fig2, n[0], n[1], alpha=.3, color=colors[i])\n",
    "grid = gridplot([[fig1, fig2]])\n",
    "show(grid)\n",
    "print(states_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "We create several types of HMMs, each of them has the same transition matrix and initial / final state probability, and a specific type of emission density: \n",
    "  * one Normal density per state with full covariance matrix\n",
    "  * one Normal density per state with diagonal covariance matrix\n",
    "  * one Normal density per state with full covariance matrix shared across states\n",
    "  * one Normal density per state with diagonal covariance matrix shared across states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = beer.graph.Graph()\n",
    "s0 = graph.add_state()\n",
    "s1 = graph.add_state(pdf_id=0)\n",
    "s2 = graph.add_state(pdf_id=1)\n",
    "s3 = graph.add_state(pdf_id=2)\n",
    "s4 = graph.add_state()\n",
    "graph.start_state = s0\n",
    "graph.end_state = s4\n",
    "graph.add_arc(s0, s1)\n",
    "graph.add_arc(s1, s1)\n",
    "graph.add_arc(s1, s2)\n",
    "graph.add_arc(s2, s2)\n",
    "graph.add_arc(s2, s3)\n",
    "graph.add_arc(s3, s3)\n",
    "graph.add_arc(s3, s1)\n",
    "graph.add_arc(s3, s4)\n",
    "graph.normalize()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.normalize()\n",
    "loop_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = beer.graph.Graph()\n",
    "s0 = graph.add_state()\n",
    "s1 = graph.add_state(pdf_id=0)\n",
    "s2 = graph.add_state(pdf_id=1)\n",
    "s3 = graph.add_state(pdf_id=2)\n",
    "s4 = graph.add_state(pdf_id=3)\n",
    "s5 = graph.add_state(pdf_id=4)\n",
    "s6 = graph.add_state(pdf_id=5)\n",
    "s7 = graph.add_state(pdf_id=0)\n",
    "s8 = graph.add_state(pdf_id=1)\n",
    "s9 = graph.add_state(pdf_id=2)\n",
    "s10 = graph.add_state()\n",
    "graph.start_state = s0\n",
    "graph.end_state = s10\n",
    "graph.add_arc(s0, s1)\n",
    "graph.add_arc(s1, s1)\n",
    "graph.add_arc(s1, s2)\n",
    "graph.add_arc(s2, s2)\n",
    "graph.add_arc(s2, s3)\n",
    "graph.add_arc(s3, s3)\n",
    "graph.add_arc(s3, s4)\n",
    "graph.add_arc(s4, s4)\n",
    "graph.add_arc(s4, s5)\n",
    "graph.add_arc(s5, s5)\n",
    "graph.add_arc(s5, s6)\n",
    "graph.add_arc(s6, s6)\n",
    "graph.add_arc(s6, s7)\n",
    "graph.add_arc(s7, s7)\n",
    "graph.add_arc(s7, s8)\n",
    "graph.add_arc(s8, s8)\n",
    "graph.add_arc(s8, s9)\n",
    "graph.add_arc(s9, s9)\n",
    "graph.add_arc(s9, s10)\n",
    "graph.normalize()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_graph = graph.compile().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the global mean/cov. matrix of the data to initialize the mixture.\n",
    "data_mean = torch.from_numpy(data.mean(axis=0)).float()\n",
    "data_var = torch.from_numpy(np.cov(data.T)).float()\n",
    "\n",
    "# HMM (diag cov).\n",
    "modelset = beer.NormalSet.create(data_mean, data_var, size=loop_graph.n_states,\n",
    "                                prior_strength=1., noise_std=1., \n",
    "                                cov_type='full')\n",
    "hmm_diag_loop = beer.HMM.create(loop_graph, modelset)\n",
    "\n",
    "modelset = beer.NormalSet.create(data_mean, data_var, size=ali_graph.n_states,\n",
    "                                prior_strength=1., noise_std=1., \n",
    "                                cov_type='full')\n",
    "hmm_diag_align = beer.HMM.create(ali_graph, modelset)\n",
    "\n",
    "models = {\n",
    "    'hmm_diag_loop': hmm_diag_loop.double(),\n",
    "    'hmm_diag_align': hmm_diag_align.double()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayes Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lrate = 1.\n",
    "X = torch.from_numpy(data).double()\n",
    "\n",
    "optims = {\n",
    "    model_name: beer.VBConjugateOptimizer(model.mean_field_factorization(), lrate)\n",
    "    for model_name, model in models.items()\n",
    "}\n",
    "\n",
    "elbos = {\n",
    "    model_name: []\n",
    "    for model_name in models\n",
    "}  \n",
    "\n",
    "inf_graphs = {\n",
    "    'hmm_diag_loop': None,\n",
    "    'hmm_diag_align': ali_graph\n",
    "}  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for name, model in models.items():\n",
    "        optim = optims[name]\n",
    "        optim.init_step()\n",
    "        elbo = beer.evidence_lower_bound(model, X, datasize=len(X),\n",
    "                                         inference_graph=inf_graphs[name],\n",
    "                                         viterbi=True)\n",
    "        elbo.backward()\n",
    "        elbos[name].append(float(elbo) / len(X))\n",
    "        optim.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'hmm_diag_loop': 'green',\n",
    "    'hmm_diag_align': 'blue'\n",
    "}\n",
    "# Plot the ELBO.\n",
    "fig = figure(title='ELBO', width=400, height=400, x_axis_label='step',\n",
    "              y_axis_label='ln p(X)')\n",
    "for model_name, elbo in elbos.items():\n",
    "    fig.line(range(len(elbo)), elbo, legend=model_name, color=colors[model_name])\n",
    "fig.legend.location = 'bottom_right'\n",
    "\n",
    "show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data.mean(axis=0)\n",
    "var = data.var(axis=0)\n",
    "std_dev = np.sqrt(max(var))\n",
    "x_range = (mean[0] - 2 * std_dev, mean[0] + 2 * std_dev)\n",
    "y_range = (mean[1] - 2 * std_dev, mean[1] + 2 * std_dev)\n",
    "global_range = (min(x_range[0], y_range[0]), max(x_range[1], y_range[1]))\n",
    "\n",
    "fig1 = figure(title='HMM (diag) loop', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig1.circle(data[:, 0], data[:, 1], alpha=.5, color='blue')\n",
    "plotting.plot_hmm(fig1, hmm_diag_loop, alpha=.1, color='blue')\n",
    "\n",
    "fig2 = figure(title='HMM (diag) align', x_range=global_range, y_range=global_range,\n",
    "              width=400, height=400)\n",
    "fig2.circle(data[:, 0], data[:, 1], alpha=.5, color='red')\n",
    "plotting.plot_hmm(fig2, hmm_diag_align, alpha=.1, color='red')\n",
    "grid = gridplot([[fig1, fig2]])\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are mixing bokeh and matplotlib >:-( ! .\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts1 = models['hmm_diag_loop'].posteriors(X).numpy().T\n",
    "posts2 = models['hmm_diag_align'].posteriors(X, ali_graph).numpy().T\n",
    "\n",
    "fig1, axarr = plt.subplots(2, 1)\n",
    "axarr[0].imshow(posts1, origin='lower')\n",
    "axarr[0].set_title('HMM loop (diag) lhs')\n",
    "axarr[1].imshow(posts2, origin='lower')\n",
    "axarr[1].set_title('HMM align (diag) lhs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
