#!/usr/bin/env bash


set -e

. path.sh


if [ $# -ne 5 ]; then
    echo "usage: <model-conf> <uttids> <dataset> <epochs> <out-dir>"
    exit 1
fi

modelconf=$1
uttids=$2
dataset=$3
epochs=$4
outdir=$5
mkdir -p $outdir

# TODO: number of jobs independent of epochs.
njobs=$epochs


# Create the units' HMM.
if [ ! -f $outdir/hmms.mdl ]; then
    beer hmm mkphones -d $dataset $modelconf $outdir/hmms.mdl || exit 1
else
    echo "units' HMM already created. Skipping."
fi


# Create the phone-loop model.
if [ ! -f $outdir/0.mdl ]; then
    beer hmm phonelist $outdir/hmms.mdl | \
        beer hmm mkphoneloopgraph - \
        $outdir/ploop_graph.pkl || exit 1
    beer hmm mkdecodegraph $outdir/ploop_graph.pkl $outdir/hmms.mdl \
        $outdir/decode_graph.pkl || exit 1
    beer hmm mkphoneloop $outdir/decode_graph.pkl $outdir/hmms.mdl \
        $outdir/0.mdl || exit 1

    # Create the optimizer of the training.
    beer hmm optimizer $outdir/0.mdl $outdir/optim_0.mdl || exit 1
else
    echo "Phone Loop model already created. Skipping."
fi

function split_() {
    njobs=$1
    outdir=$2
    uttids=$3

    mkdir -p $outdir/epoch/split/
    # split will give njobs files with a numerical name
    # used on submit_gnu_parallel, the number of files
    # generated by split_ is the same than the number
    # of processes that will be run in the computer
    split --numeric-suffixes=1 -a ${#njobs} \
        -n l/$njobs $uttids $outdir/epoch/split/

}
export -f split_;


function submit_gnu_parallel() {
    njobs=$1
    outdir=$2
    mdl=$3
    dataset=$4
    uttids=$5

    split_ $njobs $outdir $uttids

    ls -AF1 $outdir/epoch/split/* | \
        parallel --eta -j $njobs --tmpdir /var/tmp --files \
        "cat {} | beer hmm accumulate $outdir/$mdl $dataset $outdir/epoch/elbo{/.}.pkl > $outdir/epoch/beer_hmm_accumulate{/.}.log "
        
}
export -f submit_gnu_parallel;

# Training.
if [ ! -f $outdir/final.mdl ]; then
    echo "training..."

    # Retrieve the last model.
    mdl=$(find $outdir -name "[0-9]*mdl" -exec basename {} \; | \
        sort -t '.' -k 1 -g | tail -1)
    epoch="${mdl%.*}"

    # ...and the optimizer.
    optim=optim_${epoch}.mdl

    # Accumulate the statistics in parallel.
    submit_gnu_parallel $njobs $outdir $mdl $dataset $uttids

    # Update the model' parameters.
    find $outdir/epoch -name 'elbo*pkl' | \
        beer hmm update $outdir/$mdl $outdir/$optim \
        $outdir/final.mdl $outdir/optim_final.pkl || exit 1

else
    echo "Model already trained. Skipping."
fi

# Generating labels.
if [ ! -f $outdir/trans.txt ]; then
    # Creating the most likely transcription.
    echo "generating transcription for the $dataset dataset..."
    beer hmm decode --per-frame $outdir/final.mdl \
        $dataset > $outdir/trans.txt || exit 1
else
    echo "transcription already generated. Skipping."
fi

